{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to NLTK\n",
    "\n",
    "Use computers to identify patterns in language and textual data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Orientation: Where am I?\n",
    "<img src='res/launch_1.jpg'>\n",
    "\n",
    "\n",
    "<i>Credits: Kerbal space program: Falcon 9 Space X</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Our command module: Interactive python (IPython) with Jupyter Notebooks\n",
    "\n",
    "\n",
    "Let's play around with our environment:\n",
    "- Setting up and get ready with [Anaconda](https://www.continuum.io/downloads). It's free. \n",
    "- What is a notebook?\n",
    "- What can I do in the cells?\n",
    "- Most used features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Challenge: Explore the jupyter notebooks\n",
    "- Open the notebook [material](http://a.com) or make a copy for you in the cloud\n",
    "- Add 5 cells to the notebook\n",
    "- Delete 3 cells\n",
    "- Type \"Hello world\" inside the last emtpy cell and run it (we will learn how to to put more things inside Next!)\n",
    "- Move the cell to be the first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we know where we are standing... few comments:\n",
    "\n",
    "1. The main strength of IPython is that you can run bits of code individually\n",
    "2. IPython allows you to display images alongside code, and to save the input and output together.\n",
    "3. IPython makes learning a bit easier, as mistakes are easier to find and do not break an entire workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wait.. what is python?\n",
    "\n",
    "<img src='res/missionpython_cover.png'>\n",
    "\n",
    "Python is easy-to-use programming language and comes with handy / efficient tools to manipulate linguistic data. We  will learn just the basics to perform reproducible research. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is the Natural Language Toolkit?\n",
    "<img src='res/NLTK.png'>\n",
    "\n",
    "NLTK is a Python Library for working with written language data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "NLTK is free and extensively documented [here](http://www.nltk.org/).\n",
    "> Note: NLTK provides tools for tasks ranging from very simple (counting words in a text) to very complex (writing and training parsers, etc.)\n",
    "\n",
    "We will start by importing NLTK and explore some data available for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import nltk library\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have data to work with you can use NLTK sample data. Here how you can access to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# get some example data from nltk\n",
    "# asterisk means 'everything'\n",
    "# from nltk.corpus import *\n",
    "from nltk.corpus import gutenberg\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sentences=gutenberg.sents('shakespeare-macbeth.txt')\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# explore the raw text\n",
    "words=gutenberg.words('shakespeare-macbeth.txt')\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A list of all possible texts available for the guttenberg corpus can be printed here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Explore more at http://www.gutenberg.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variables\n",
    "We use variables to name temporary data in the computer.\n",
    "Think of it as a nickname so we can use our data in other parts of the notebook.\n",
    "Try to assign a variable to our text \"hello world!\".\n",
    ">Hint: Don't forget quotes when writing text.\n",
    "\n",
    "```python\n",
    "greetings='Hello world!'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "greetings='Hello world!'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, call your variable by the nickname:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "greetings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# call the variable sentences\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can assign other type of data to variables, like numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "age=30\n",
    "age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is good to choose meaningful variable names to remind you — and to help anyone else who reads your Python code — what your code is meant to do. Python does not try to make sense of the names; it blindly follows your instructions, and does not object if you do something confusing, such as ```one = 'two'``` or ```two = 3```. The only restriction is that a variable name cannot be any of Python's reserved words, such as def, if, not, and import. If you use a reserved word, Python will produce a syntax error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "one=2\n",
    "one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Variables can give a name to lot of things, we call this **objects**, Python’s abstraction for data. All data in a Python program is represented by objects or by relations between objects. \n",
    "We will use operations with this objects which we call **methods** and **functions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python as a calculator\n",
    "We can use the iPython environment as a caluculator; try doing some basic mathematics with python. *Hint*: use * and / like your smartphone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# multiplication\n",
    "4*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# division \n",
    "20/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can make operations between objects using **operators**.\n",
    "Operators are important and we can do more with them than multiply. We can ask IPython if something is equal to **==** or not equal to **!=** and a number of others. Try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# comparison\n",
    "'hello'=='Hello'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Methods and functions\n",
    "\n",
    "<img src='res/methods_functions.jpg'>\n",
    "\n",
    "<i>Credits: Kerbal space program: Falcon 9 Space X</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The syntax we'll use the most involves two types of commands: \"functions and methods\"; one that look like this ```len()``` and anothers that look like this ```.split()```\n",
    "\n",
    "Both need an object (text data in our case) to work on; for example, ```len(text1)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(greetings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(greetings) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python basics: A summary\n",
    "\n",
    "- Syntax = Set of rules to define how python is written\n",
    "- Python is designed to be highly readable\n",
    "- Uses english keywords which are easy to understand\n",
    "- Besides \"Objects\", we will start using \"functions\" and \"methods\": pieces of code already written that we can reuse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick start: Let computers do the reading and count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploring vocabulary:  Useful functions\n",
    "\n",
    "NLTK makes it really easy to get basic information about the size of a text and the complexity of its vocabulary using **python functions**.\n",
    "*Please* note that all these commands use the same *syntax*; this is the first python syntax we'll learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```len(text1)``` gives the number of symbols or 'tokens' in your text. E.g. words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```set(text2)``` gives you a list of all the tokens in the text, without the duplicates. Hence, ```len(set(text3))``` will give you the total number unique tokens. Remember this still includes punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(set(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```sorted(text4)``` places items in the list into alphabetical order, with punctuation symbols and capitalised words first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sorted(greetings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge: Lexical richness\n",
    "\n",
    "We can investigate the *lexical richness* of a text. For example, by dividing the total number of words by the number of unique words, we can see the average number of times each word is used. \n",
    "\n",
    "For this challenge you will have to combine your knowledge of the syntax we've learnt so far and iPython's mathematical abilities.\n",
    "\n",
    "Have a go at calculating the lexical richness of text3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#words\n",
    "len(words)/len(set(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge: Percentaje taken by a word in text\n",
    "Store in a variable the amount of times the word \"love\" is in the text. Then calculate the percentaje taken up by this word in the whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "love_count=50\n",
    "love_count/len(words)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load your own text\n",
    "<img src='res/text.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are several ways to do this, here we will discuss two options and you can see at the end of notebook another option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the notebook, it is assumed you have downloaded [here](https://transfer.sh/KGhz3/papers_text.txt) the dataset and placed on a ``data`` folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains more than 7K papers from NiPS conference. You can find more about this conference here: https://nips.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# https://transfer.sh/KGhz3/papers_text.txt\n",
    "text_raw=\"\"\n",
    "with open(\"data/tweets.txt\",'r') as text_file:\n",
    "    text_raw=text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Congratulations! You have loaded all tweets! You just made the computer read all this data for you. Let me show you other ways to do this which we will use during the workshop for practical reasons:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We are interested in words and sentences. In our first lessons, we analyzed texts already presented as words and sentences, we can do this with an operation called \"tokenization\"\n",
    "\n",
    "**Tokenization = cut the text into pieces like sentences or words**\n",
    "<img src=\"res/token.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize,sent_tokenize,wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_words=word_tokenize(text_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twitter_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploring text - useful methods to search inside text\n",
    "NLTK has useful methods that helps us to work with text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use methods from the object **text** to count the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text=nltk.Text(twitter_words)\n",
    "text.vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Object **Text** is very handful, it wraps a lot of functionality. Let me show you some useful methods in this object:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Concordance** shows you a word in context and is useful if you want to be able to discuss the ways in which a word is used in a text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text.concordance('greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Similar** will find words used in similar contexts; it is not looking for synonyms, although the results may include synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text.similar('Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Common contexts** allows us to examine just the contexts that are shared by two or more words, such as monstrous and very. We have to enclose these words by square brackets as well as parentheses, and separate them with a comma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text.common_contexts(['Greens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also find words that typically occur together, which tend to be very specific to a text or genre of texts. A **collocation** is a sequence of words that occur together unusually often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge: Text exploration\n",
    "\n",
    "1. Find the collocations in one of the papers (or all) \n",
    "\n",
    "2. Chose one of the words to concordance. \n",
    "\n",
    "3. Investigate how the word is used. What words are used similarly? \n",
    "\n",
    "4. And what are the common contexts of these words? \n",
    "\n",
    "5. Report your findings to the person next to you. \n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploring text: Plotting dispersion of words\n",
    "If we can find words in a text, we can also take note of their position within the text, Python lets you create graphs to analize textual data.\n",
    "We can then generate a **dispersion plot** that shows where given words occur in a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text.dispersion_plot(['Greens','Labor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge: Dispersion of words in a text\n",
    "\n",
    "Create a dispersion plot for other terms.\n",
    "What do you think it tells you? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text.dispersion_plot(['immigration','VoteSustainable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here, VoteSustainable is a term used regularlly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data structures: Texts as Lists of Words\n",
    "Python treats a text as a long list of words. First, we'll make some lists of our own, to give you an idea of how a list behaves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sent1 = ['Call', 'me', 'Ishmael', '.']\n",
    "# Note we use Square brackets here to define our list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A few things to consider...\n",
    "<br>\n",
    "<img src='res/lists.jpg'>\n",
    "*Credit: Head First Python by Paul Barry*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can add lists together, creating a new list containing all the items from both lists. You can do this by typing out the two lists or you can add two or more pre-defined lists. This is called concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2=[\"hi\",'you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sent1+sent2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can think of text as a concatenation of sentences, and sentences as a concatenation of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What if we want to add a single item to a list? This is known as appending. When we append() to a list, the list itself is updated as a result of the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sent1.append('Now!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Indexing Lists\n",
    "We can navigate this list with the help of indexes. Just as we can find out the number of times a word occurs in a text, we can also find where a word first occurs. We can navigate to different points in a text without restriction, so long as we can describe where we want to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(sent1.index('me')) # print is a python function we can use to show the result of an text operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This works in reverse as well. We can ask Python to locate the 158th item in our list (note that we use square brackets here, not parentheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sent1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As well as pulling out individual items from a list, indexes can be used to pull out selections of text from a large corpus to inspect. We call this **slicing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text[1000:1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we're asking for the beginning or end of a text, we can leave out the first or second number. For instance, [:5] will give us the first five items in a list while [8:] will give us all the elements from the eighth to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sent1[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To help you understand how indexes work, let's create one.\n",
    "We start by defining the name of our index and then add the items. You probably won't do this in your own work, but you may want to manipulate an index in other ways. Pay attention to the quote marks and commas when you create your test sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sent_test=['one','two','three','four']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_test[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the first element in the list is zero. This is because we are telling Python to go zero steps forward in the list. If we use an index that is too large (that is, we ask for something that doesn't exist), we'll get an error.\n",
    "We can modify elements in a list by assigning new data to one of its index values. We can also replace a slice with new material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sent_test[2]=\"change three\"\n",
    "sent_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge: Lists \n",
    "\n",
    "Take a few minutes to define a sentence of your own and modify individual words and groups of words (slices) using the same methods used earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sent=['Today','is','a','rainy','day']\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent[4]='cloudy'\n",
    "sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Strings: A useful object to store texts\n",
    "\n",
    "A string is a sequence of characters, you can think of it as a list. For example, we can assign a string to a variable, index a string, and slice a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "name='Julia'\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "name[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also make some mathematical operations, like \n",
    "```+``` and ```*```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "name*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can ```join```\n",
    " the words of a list to make a single string, or ```split```\n",
    " a string into a list, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "blank=' '\n",
    "sent=blank.join(['I','love','python'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And it will be helpful to normalize your text. E.g. lowercase, uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "animal1='Elephant'\n",
    "animal2='elephant'\n",
    "animal1.lower()==animal2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let computers do the repetitive work: Python Loops\n",
    "\n",
    "We can use Python to automate tasks, such as performing a function on all items in a list. For instance, we could ask it to tell us the size of all the files in a directory. To do that, we'll have to teach the computer how to repeat things. We do this by creating something called a *loop*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An example task that we might want to repeat is printing each character in a word on a line of its own. One way to do this would be to use a series of print statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(animal1[0])\n",
    "print(animal1[1])\n",
    "print(animal1[2])\n",
    "print(animal1[4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are the cons of doing this do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(animal1[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can make mistakes using a particular index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='res/loop.jpg'>\n",
    "<br>\n",
    "<i>Credit: Head First Python by Paul Barry</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is call a 'for loop'. Try it with other words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The general form of a loop is:\n",
    "```python\n",
    "for variable in collection:\n",
    "    # do this\n",
    "    # do that\n",
    "    ```\n",
    "We can call the loop variable whatever we want, but there must be a colon at the end of the line starting the loop, and we must indent anything we want to run inside the loop. This is used to signify when the loop ends, instead of using a symbol to end the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is a loop that repeatedly updates a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "length = 0\n",
    "for char in 'Python':\n",
    "    length = length + 1\n",
    "print('There are', length, 'letters in this word')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let's go through this line by line.\n",
    "The variable is set to 0, so that python starts counting from 0.\n",
    "The second line opens a for loop that loops over the characters in Python.\n",
    "Now, the third line tells python to count by one, pretty obvious to us humans... Since there are six characters in 'Python', the statement on line 3 will be executed five times.\n",
    "The first time around, length is zero (the value assigned to it on line 1). The statement adds 1 to the old value of length, producing 1, and updates length to refer to that new value. The next time around, char is 'y' and length is 1, so length is updated to be 2. After four more updates, length is 6.\n",
    "Since there is nothing left in 'Python', the loop finishes and the print statement on line 4 tells us our final answer inbetween two strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Of course, we already know that we could use ```len()``` to find the length of a string, but it's just an example... Let's compare results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(len('Python'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now for another example using a list! Fruit salad, yummy, yummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fruits = ['banana', 'apple', 'mango']\n",
    "for fruit in fruits:        \n",
    "    print('Current fruit :', fruit)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge: Loops\n",
    "Define a list called Library with the first 10 papers. Write a for loop that will  print the lexical diversity over each paper and tell you its score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "library=[\"hi dear\",\"how come\",\"are you happy\",\"you\"]\n",
    "for book in library:\n",
    "    score=len(book)/len(set(book))\n",
    "    print(book,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Frecuency Distributions: Counting for analysis\n",
    "We can use Python's ability to perform statistical analysis of data to do further exploration of vocabulary. For instance, we might want to be able to find the most common or least common words in a text. We'll start by looking at frequency distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import FreqDist from the nltk.probability module\n",
    "from nltk.probability import FreqDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fdist1=FreqDist(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fdist1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fdist1=text.vocab()\n",
    "fdist1.most_common(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge: Frequency distributions\n",
    "Use a loop to compare the 10 most common words of the texts. Give a pair: paper, most common words. Plot one of the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fdist1.plot(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploring vocabulary (cont.)\n",
    "As well as counting individual words, we can count other features of vocabulary, such as how often words of different lengths occur. We do this by putting together a number of the commands we've already learned.\n",
    "\n",
    "We could start like this: \n",
    "\n",
    "```[len(word) for word in text1]```\n",
    "\n",
    "... but this would print the length of every word in the whole book, so let's skip that bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# try get the frequency distribution for the lenght of words in first paper\n",
    "list_words=[]\n",
    "for word in text:\n",
    "    list_words.append(len(word))\n",
    "    \n",
    "fdist=FreqDist(list_words)\n",
    "count=fdist.most_common(5)\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proportion of the top word with the whole text\n",
    "242094/len(list_words) # 242094 = fdist.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.freq(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# what is the most common word lenght?\n",
    "fdist.most_common(1)\n",
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# how frequent is that length in the overall text?\n",
    "fdist.most_common(1)\n",
    "# 242094 times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These last two commands tell us that the most common word length, and that these account for about 20% of the text. We can see this just by visually inspecting the list produced by ```fdist2.most_common()```\n",
    ", but if this list were too long to inspect readily, or we didn't want to print it, there are other ways to explore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are a number of functions defined for NLTK's frequency distributions:\n",
    "\n",
    " | Function | Purpose  |\n",
    " |--------------|------------|\n",
    " | fdist = FreqDist(samples) | create a frequency distribution containing the given samples |\n",
    " | fdist[sample] += 1 | increment the count for this sample |\n",
    " | fdist['monstrous']  | count of the number of times a given sample occurred |\n",
    " | fdist.freq('monstrous') | frequency of a given sample |\n",
    " | fdist.N()  |  total number of samples |\n",
    " | fdist.most_common(n)   |  the n most common samples and their frequencies |\n",
    " | for sample in fdist:   |  iterate over the items in fdist, when in the loop, we refer to each item as sample |\n",
    " | fdist.max() | sample with the greatest count |\n",
    " | fdist.tabulate()   |  tabulate the frequency distribution |\n",
    " | fdist.plot()  |   graphical plot of the frequency distribution |\n",
    " | fdist.plot(cumulative=True) | cumulative plot of the frequency distribution |\n",
    " | fdist1 < fdist2 | test if samples in fdist1 occur less frequently than in fdist2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is possible to select the longest words in a text, which may tell you something about its vocabulary and style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(text)\n",
    "long_words=[]\n",
    "for word in vocab:\n",
    "    if len(word)>7: #pick a treshold\n",
    "        long_words.append(word)\n",
    "        \n",
    "sorted_words=sorted(long_words)\n",
    "print(sorted_words[:10]) # print the first ten, otherwise it will print too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this other template to do exactly the same thing, in just one line. We are not going to go deep in this but if you are interested it's called **List comprehension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vocab = set(text)\n",
    "long_words = [word for word in vocab if len(word) == 15]\n",
    "sorted_words=sorted(long_words)\n",
    "print(sorted_words[:10]) # print the first ten, otherwise it will print too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also use numerical operators to refine the types of searches we ask Python to run. We can use the following relational operators:\n",
    "\n",
    "\n",
    "### Common relationals\n",
    " |  Relational | Meaning |\n",
    " |--------------:|:------------|\n",
    " | <    |  less than |\n",
    " | <=   |   less than or equal to |\n",
    " | ==  |    equal to (note this is two \"=\" signs, not one) |\n",
    " | !=   |   not equal to |\n",
    " | \\>   |   greater than |\n",
    " | \\>= |   greater than or equal to |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge: Use operator to explore text\n",
    "\n",
    "Using the corpus, use the relational operators above to find:\n",
    "- Words longer than four characters\n",
    "- Words of four or more characters\n",
    "- Words of exactly four characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Words longer than four characters\n",
    "\n",
    "long_words = [word for word in vocab if len(word) > 4]\n",
    "sorted_words=sorted(long_words)\n",
    "print(sorted_words[:10]) # print the first ten, otherwise it will print too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Words of four or more characters\n",
    "long_words = [word for word in vocab if len(word) >= 4]\n",
    "sorted_words=sorted(long_words)\n",
    "print(sorted_words[:10]) # print the first ten, otherwise it will print too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words of exactly four characters\n",
    "long_words = [word for word in vocab if len(word) == 4]\n",
    "sorted_words=sorted(long_words)\n",
    "print(sorted_words[:10]) # print the first ten, otherwise it will print too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can fine-tune our selection even further by adding other conditions. For instance, we might want to find long words that occur frequently (or rarely).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge: Search with conditions\n",
    "\n",
    "Can you find all the words in a text that are more than seven letters long and occur more than seven times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "long_words = [word for word in vocab if len(word) > 7 and fdist1[word]>7 ] # we created fdist1 before as the distribution of words in the text\n",
    "sorted_words=sorted(long_words)\n",
    "print(sorted_words[:10]) # print the first ten, otherwise it will print too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Common methods for strings\n",
    "\n",
    " | Operator  | Purpose  |\n",
    " |--------------|------------|\n",
    " | s.startswith(t) | test if s starts with t |\n",
    " | s.endswith(t)  |  test if s ends with t | \n",
    " | t in s         |  test if t is a substring of s | \n",
    " | s.islower()    |  test if s contains cased characters and all are lowercase | \n",
    " | s.isupper()    |  test if s contains cased characters and all are uppercase | \n",
    " | s.isalpha()    |  test if s is non-empty and all characters in s are alphabetic | \n",
    " | s.isalnum()    |  test if s is non-empty and all characters in s are alphanumeric | \n",
    " | s.isdigit()    |  test if s is non-empty and all characters in s are digits | \n",
    " | s.istitle()    |  test if s contains cased characters and is titlecased (i.e. all words in s have initial capitals) | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# get all the words from text 1 that ends with 'ality'\n",
    "some_words = [word for word in vocab if word.endswith('ality') ] # we created fdist1 before as the distribution of words in the text\n",
    "sorted_words=sorted(some_words)\n",
    "print(sorted_words[:10]) # print the first ten, otherwise it will print too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge\n",
    "\n",
    "You'll remember right at the beginning we started looking at the size of the vocabulary of a text, but there were two problems with the results we got from using:\n",
    "\n",
    "```len(set(text1))```\n",
    "\n",
    "This count includes items of punctuation and treats capitalised and non-capitalised words as different things (*This* vs *this*). We can now fix these problems. We start by getting rid of capitalised words, then we get rid of the punctuation and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Normalize by lower case\n",
    "some_words = [word.lower() for word in vocab] \n",
    "some_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Get rid of numbers and punctuation\n",
    "print(\"Before:\", len(some_words))\n",
    "some_words = [word for word in vocab if word.isalpha()]\n",
    "print(\"After:\", len(some_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working your own text (cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have a big string, that means, a sequence of characters. We already know how to work on this. For example, can we know the size of this string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(text_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text_raw[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize,sent_tokenize,wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## get the word tokens\n",
    "words=word_tokenize(text_raw[:20000]) # only for practical reasons I'm taking a portion of the text. You should remove the slicing.\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create a text object out of the tokens\n",
    "text10=nltk.Text(words)\n",
    "text10.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge: Explore your vocabulary with your text\n",
    "\n",
    "Get a text of your own\n",
    "\n",
    "1. Explore the lexical richness\n",
    "2. Calculate the percentage taken by a word\n",
    "3. Find the collocations\n",
    "4. Chose one of the words to concordance. \n",
    "5. Investigate how the word is used\n",
    "6. Create a dispersion plot\n",
    "7. Create a frequency distribution\n",
    "8. Get the top 50 words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was done in previous challenges. I will encourage you to take your own text here and explore it!! Have Fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Structuring the code: Writing our own functions (yay!)\n",
    "One thing that makes Python unique is that whitespace at the start of the line (use four spaces for consistency!) is meaningful. In many other languages, whitespace at the start of lines is simply a readability convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Fix this whitespace problem!\n",
    "\n",
    "string = 'user'\n",
    "if string == 'user':\n",
    "print('Phew, fixed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, whitespace tells both Python and human readers where things start and stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Defining a function\n",
    "\n",
    "<img src='res/function.jpg'>\n",
    "\n",
    "*Credit: Head First Python by Paul Barry*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def welcomer(name):\n",
    "    print('Welcome, %s!' % name)# here '%s' tells Python to expect a string and how many strings to expect.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here, the word 'name' is a placeholder. It stands in for any argument we might care to place in the brackets. The placeholder could be anything. It could be n or fsdlkfjs; it will still work. What matters for the program is that you use the same one consistently. On the other hand, what matters for us is that you use descriptive names so you remember what the code does!\n",
    "Notice that it doesn't do anything by itself. It needs to actually be called, and given some data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that it doesn't do anything by itself. It needs to actually be called, and given some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "welcomer('jack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Challenge: Functions\n",
    "Previously, we calculated the lexical diversity of a text. In NLTK, we can create a function called lexical diversity that runs a single line of code. We can then call this function to quickly determine the lexical density of a corpus or subcorpus. Challenge!\n",
    "Write a function to calculate the lexical diversity of a text; test it out on the books in the NLTK corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(text)/len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#After the function has been defined, we can run it:\n",
    "lexical_diversity(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Other functions that we've used already include ```len()``` and ```sorted()``` - these were predefined. ```lexical_diversity()```\n",
    " is one we set up ourselves; note that it's conventional to put a set of parentheses after a function, to make it clear what we're talking about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**--bonus--**\n",
    "#### Challenge: Functions to set up our text from the web \n",
    "Write a function that receives a URL (internet address where the text is) and return an object ```Text```\n",
    " that you can use to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "802.6666870117188px",
    "left": "22px",
    "top": "137.6666717529297px",
    "width": "333.9705810546875px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
